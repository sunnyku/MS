Let’s reiterate what you have learnt till now:

    You started with a scatter plot to check the relationship between sales and marketing budget.

    You found residuals and RSS for any given line passing through the scatter plot.

    Then you found the equation of the best-fit line by minimising the RSS and found the optimal value of β₀ and β₁.

    The Ordinary Least Squares method has the criterion of the minimisation of the sum of squares of residuals. Residuals are defined as the difference between the y-coordinates of actual data and the y-coordinates of predicted data.
The criterion is given by the Ordinary Least Squares (OLS) method, which states that the sum of squares of residuals should be minimum. This is explained by this option.

Gradient Descent is an optimisation algorithm which optimises the objective function (for linear regression it's cost function) to reach to the optimal solution.


The residuals for all 5 points are -0.5, 1, 0, -2, 1. The sum of squares of all 5 residuals would be 0.25 + 1 + 0 + 4 + 1 = 6.25


14
✓ Correct
Feedback:

The average of y-value for all data points (3 + 5 + 5 + 4 + 8)/5 = 25/5 = 5. So y−¯y term for each data point would be -2, 0, 0, -1, 3. So, the squared sum of these terms would be 4 + 0 + 0 + 1 + 9 = 14.


R² value is given by 1 - (RSS / TSS). So, in this case, R² value would be 1 - (6.25 / 14).


Here's a brief summary of what you learned in this session:

    Machine learning models can be classified into following two categories on the basis of learning algorithm:
        Supervised learning method: Past data with labels is available to build the model
            Regression: The output variable is continuous in nature
            Classification: The output variable is categorical in nature
        Unsupervised learning method: Past data with labels are not available
            Clustering: No pre-defined notion of labels is there
    Past data set is divided into two parts during supervised learning method:
        Training data  is used for the model to learn during modelling
        Testing data is used by the trained model for prediction and model evaluation
    Linear regression models can be classified into two types depending upon the number of independent variables:
        Simple linear regression: When the number of independent variables is 1
        Multiple linear regression: When the number of independent variables is more than 1
    The equation of the best fit regression line Y = β₀ + β₁X can be found by minimising the cost function (RSS in this case, using the Ordinary Least Squares method) which is done using the following two methods:
        Differentiation
        Gradient descent method
    The strength of a linear regression model is mainly explained by R²,  where R² = 1 - (RSS / TSS)
        RSS: Residual Sum of Squares
        TSS: Total Sum of Squares


Correct! The value of the correlation coefficient always lies between -1 and 1, where a negative value implies a negative correlation, a positive value shows a positive correlation, and a zero value shows no correlation.


Feedback:

Correct! The value of R-squared lies between 0 and 1, where 1 implies that the variance in the data is being explained by the model, and 0 implies that none of the variance values is being explained by the model. Obviously, it is very difficult to achieve either of the extreme values.


1 and 1
✓ Correct
Feedback:

Notice that the relationship between X and y is perfectly linear in both cases. Their slopes are 1 and 0.5. But since all the points lie on the straight line, the correlation coefficient would be 1. The slope of the straight line does not determine the correlation between the variables.
Correct! The absolute value of the correlated coefficient is very high. The negative sign just implies that X and y are negatively correlated. Hence, they have a very strong negative correlation.

The linear relation between X and Y is strong, and their correlation will be negative.
✓ Correct
Feedback:

A higher value of R² means a strong linear relation. As Y is decreasing with the increasing value of X, you can conclude that their correlation will be negative.

The algorithm has to distinguish between actual emergency shakes and everyday jostling. Here, your output variable has predefined labels (shake/jostle), which are categorical in nature. So, this is a supervised learning-classification problem.In the linear regression equation, X gets multiplied by 1.6 with no change in Y. So, the slope will be divided by 1.6.






