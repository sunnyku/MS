import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Lasso, Ridge
from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import r2_score
# Suppress warnings
import warnings
warnings.filterwarnings(action = 'ignore')


#load data https://drive.google.com/file/d/1tX62d7cA8Vb_5zOEuhwjE5vLZ5aq7RjG/view?usp=drive_link
df = pd.read_csv("model_selection_data.csv")


df.head()


# The Boston Housing Dataset
# The Boston Housing Dataset is a derived from information collected by the U.S. Census Service concerning housing in the area of Boston MA.
# The following describes the dataset columns:
# CRIM - per capita crime rate by town
# ZN - proportion of residential land zoned for lots over 25,000 sq.ft.
# INDUS - proportion of non-retail business acres per town.
# CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)
# NOX - nitric oxides concentration (parts per 10 million)
# RM - average number of rooms per dwelling
# AGE - proportion of owner-occupied units built prior to 1940
# DIS - weighted distances to five Boston employment centres
# RAD - index of accessibility to radial highways
# TAX - full-value property-tax rate per $10,000
# PTRATIO - pupil-teacher ratio by town
# B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
# LSTAT - % lower status of the population
# MEDV - Median value of owner-occupied homes in $1000's


#check for missing value
df.isnull().mean()


df.shape


X=df.drop(["Target"],axis=1)
y=df["Target"]


#split data into training and test sets
X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=42)


print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)





#base model
# data--> standardscalling-->polynomialfeatures-->linerregression


liner_reg_pipeline = make_pipeline(StandardScaler(),PolynomialFeatures(degree=2),LinearRegression())
liner_reg_pipeline.fit(X_train,y_train)


# Predictions
y_pred_liner_reg_train = liner_reg_pipeline.predict(X_train)
y_pred_liner_reg_test = liner_reg_pipeline.predict(X_test)



# R2 calculation
r2_liner_reg_train = r2_score(y_train, y_pred_liner_reg_train)
r2_liner_reg_test = r2_score(y_test, y_pred_liner_reg_test)


print("Training R-sq:")
print(f"Linear Reg:{r2_liner_reg_train:.2f}")
print("Testing R-sq:")
print(f"Linear Reg:{r2_liner_reg_test:.2f}")





# alpha is pentelty parameter
ridge_reg_pipeline = make_pipeline(StandardScaler(),PolynomialFeatures(degree=2), Ridge(alpha=84))
ridge_reg_pipeline.fit(X_train,y_train)



# Predictions
y_pred_ridge_reg_train = ridge_reg_pipeline.predict(X_train)
y_pred_ridge_reg_test = ridge_reg_pipeline.predict(X_test)



r2_ridge_reg_train = r2_score(y_train, y_pred_ridge_reg_train)
r2_ridge_reg_test = r2_score(y_test, y_pred_ridge_reg_test)


print("Training R-sq:")
print(f"Ridge Reg:{r2_ridge_reg_train:.2f}")
print("Testing R-sq:")
print(f"Ridge Reg:{r2_ridge_reg_test:.2f}")


# train and test both should be high but difference should be minimal
# alpha =85 train= 89 test = 82


print("Training R-sq:")
print(f"Linear Reg:{r2_liner_reg_train:.2f}")
print("Testing R-sq:")
print(f"Linear Reg:{r2_liner_reg_test:.2f}")


# alpha is pentelty parameter
ridge_reg_pipeline = make_pipeline(MinMaxScaler(),PolynomialFeatures(degree=2), Ridge(alpha=0.02))
ridge_reg_pipeline.fit(X_train,y_train)



# Predictions
y_pred_ridge_reg_train = ridge_reg_pipeline.predict(X_train)
y_pred_ridge_reg_test = ridge_reg_pipeline.predict(X_test)



r2_ridge_reg_train = r2_score(y_train, y_pred_ridge_reg_train)
r2_ridge_reg_test = r2_score(y_test, y_pred_ridge_reg_test)


print("Training R-sq:")
print(f"Ridge Reg:{r2_ridge_reg_train:.2f}")
print("Testing R-sq:")
print(f"Ridge Reg:{r2_ridge_reg_test:.2f}")





# alpha is pentelty parameter
lasso_reg_pipeline = make_pipeline(StandardScaler(),PolynomialFeatures(degree=2), Lasso(alpha=.45))
lasso_reg_pipeline.fit(X_train,y_train)


# Predictions
y_pred_lasso_reg_train = lasso_reg_pipeline.predict(X_train)
y_pred_lasso_reg_test = lasso_reg_pipeline.predict(X_test)


r2_lasso_reg_train = r2_score(y_train, y_pred_lasso_reg_train)
r2_lasso_reg_test = r2_score(y_test, y_pred_lasso_reg_test)


print("Training R-sq:")
print(f"Lasso Reg:{r2_lasso_reg_train:.2f}")
print("Testing R-sq:")
print(f"Ridge Reg:{r2_lasso_reg_test:.2f}")


# alpha is pentelty parameter
lasso_reg_pipeline = make_pipeline(MinMaxScaler(),PolynomialFeatures(degree=2), Lasso(alpha=0.021))
lasso_reg_pipeline.fit(X_train,y_train)


# Predictions
y_pred_lasso_reg_train = lasso_reg_pipeline.predict(X_train)
y_pred_lasso_reg_test = lasso_reg_pipeline.predict(X_test)


r2_lasso_reg_train = r2_score(y_train, y_pred_lasso_reg_train)
r2_lasso_reg_test = r2_score(y_test, y_pred_lasso_reg_test)


print("Training R-sq:")
print(f"Lasso Reg:{r2_lasso_reg_train:.2f}")
print("Testing R-sq:")
print(f"Ridge Reg:{r2_lasso_reg_test:.2f}")


# Best result for all iteration
# alpha =85 train= 89 test = 82 (Ridge _ stdscaller)  -- rejected
# alpha =2 train= 89 test = 84 (Ridge _ minmaxscaller) -- first choise 
# alpha =0.45 train= 83 test = 78 (lasso _ stdscaller) -- rejected
# alpha =0.21 train= 85 test = 82 (Ridge _ minmaxscaller) -- 2nd choice -- may be overfit
## outcomes
## minmaxscaler works better thanks stdscaller




