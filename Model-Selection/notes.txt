How to extrapolate learnings from a finite amount of data to explain or predict all possible inputs of the same type

✓ Correct
Feedback:
Machine learning does not simply involve building models to fit the available data. The real challenge is to find patterns that can be used to explain the behaviour of similar unseen data.

Occam’s razor does not suggest that a model should be unjustly simplified until no further simplification is possible. It suggests that when faced with a trade-off between a complex and a simple model, with all other things being roughly equal, you are better off choosing the simpler one. The reason for this will be explained shortly.


Occam's razor is perhaps the most important thumb rule in machine learning and is incredibly 'simple' at the same time. When in dilemma, choose the simpler model.

A learning algorithm's task is to figure out what needs to be done and how. In linear regression, for example, the learning algorithm optimises the cost function and produces the models, i.e., the coefficients.

The learning algorithm is instructed what needs to be done; it figures out how it needs to be done and returns a model.


Simpler models are generic, i.e., they apply to a wider range of data.

✓ Correct
￼
Complex models make assumptions about the data, which are likely to be wrong.

✓ Correct
You missed this!
￼
Simpler models require less training data compared with complex models.

✓ Correct
￼
Simpler models are more robust.

Models are trained on a set of training data, but their efficacy is determined by their ability to perform well on unseen (test) data.

✓ Correct
Feedback:
It is possible to memorise the training data while failing to truly learn the underlying trends and patterns. On unseen data (read tricky but unseen exam questions), memorising is bound to fail.

If the training accuracy is higher than 10%, it is likely to have overfitted. Neural networks, that you will learn about later, can be made extremely complex using a number of hyperparameters such as hidden layers and the number of neurons. However, the basic idea remains the same - memorisation of training data and failure on test data.


 usage of a simpler model wherever possible:

A simpler model is usually more generic than a complex model. This becomes important because generic models are bound to perform better on unseen data sets.
A simpler model requires fewer training data points. This becomes extremely important because in many cases, one has to work with limited data points.
A simple model is more robust and does not change significantly if the training data points undergo small changes.
A simple model may make more errors in the training phase but is bound to outperform complex models when it views new data. This happens because of overfitting.


The ‘variance’ of a model is the variance in its output on some test data with respect to the changes in the training data. In other words, variance here refers to the degree of changes in the model itself with respect to changes in the training data.

 

Bias quantifies how accurate the model is likely to be on future (test) data. Extremely simple models are likely to fail in predicting complex real-world phenomena. Simplicity has its own disadvantages.


Hyperparameters are parameters that we pass on to the learning algorithm to control the complexity of the final model. They are choices that the algorithm designer makes to ‘tune’ the behaviour of the learning algorithm. Therefore, the choice of hyperparameters has a lot of bearing on the final model produced by the learning algorithm.


the concept of hyperparameters has been summarised below.

Hyperparameters are used to 'fine-tune' or regularize the model to keep it optimally complex.
The learning algorithm is given the hyperparameters as the input, and it returns the model parameters as the output.
Hyperparameters are not part of the final model output.


the problems associated with manual hyperparameter tuning are as follows:

Split into train and test sets: Tuning a hyperparameter makes the model 'see' the test data. Also, the results are dependent on the specific train-test split.
Split into train, validation and test sets: The validation data would eat into the training set.

However, in cross-validation, you split the data into train and test sets and train multiple models by sampling the train set. Finally, you only use the test set to test the hyperparameter once.

The following three key steps are to be taken while tuning the hyperparameters in Python:

Create a cross-validation scheme: For example, the number of splits that you want to set
Specify the range of hyperparameters to tune
Perform a grid search on the set range


The results for grid search can be viewed using the following code:

pd.DataFrame(model_cv.cv_results_)



The various types of cross-validation are as follows:

K-fold cross-validation
Leave one out (LOO) cross-validation
Leave P-out (LPO) cross-validation
Stratified K-Fold cross-validation


Any model needs to be tested on how well it would work in the proverbial ‘real’ world because once a model has seen the data, it can attempt to ‘memorise’ it, and once that is done, testing it on the same data set will not help in determining its performance on unseen data. In an ideal scenario wherein we have plenty of data, we should divide the data into three sets. The first one would be the training data on which we shall train the model. The second one would be the validation data on which we shall test the model and tune the hyperparameters. The third one would be the test data that we will use for assessing our model.

Weak learners create simpler models that have a lower variance. They are not able to model complex relationships and, hence, create a more generic model.

Regularization does not improve accuracy; it improves the balance between accuracy and complexity.
impler models will always have fewer test errors than a complex model.

✓ Correct
Feedback:
Complex models, assuming that you have enough training data available, can do a quite accurate job of prediction.

